{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motif Detection of Every Gene Detected in Experimental Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teague McCracken \n",
    "03/30/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the notebook, set environment to transcriptomics\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import multiprocessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Extract promoter sequences for each gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs needed: <br>\n",
    "1. gtf_file (reference genome information) <br>\n",
    "2. gene_list_file (detected genes from experiment) <br>\n",
    "3. genome.fa <br>\n",
    "4. genomes size file Arabidopsis.genome (contains genome size information) <br>\n",
    "\n",
    "Outputs: all outputs go to project checkpoint folder <br>\n",
    "1. filtered_gtf (reduced version of Arabidopsis gtf file) <br>\n",
    "2. tss.bed (bed format with transcription start sites) <br>\n",
    "3. promoters.bed (bed format with 1000 bp upstream regions (promoters) of genes) <br>\n",
    "4. promoters.fasta (the final output, sequences of promoter regions of each gene of interest) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for step 1\n",
    "gtf = \"/home/temccrac/Programs/data/genomes/Arabidopsis_thaliana.TAIR10.54.gtf\"\n",
    "gene_list = \"/home/temccrac/Programs/git_clones/ECE759_Project/cellular_clarity/genes_of_interest.txt\"\n",
    "genome_fa = \"/home/temccrac/Programs/data/genomes/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa\"\n",
    "genome_sizes = \"/home/temccrac/Programs/data/genomes/Arabidopsis.genome\"\n",
    "\n",
    "checkpoint_path = '/home/temccrac/Programs/cellular_clarity_project/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core functions for promoter extraction\n",
    "def filter_gtf_by_genes(gtf_file, gene_list_file, output_gtf):\n",
    "    with open(gene_list_file, 'r') as f:\n",
    "        genes = set(f.read().splitlines())\n",
    "\n",
    "    with open(gtf_file, 'r') as gtf_in, open(output_gtf, 'w') as gtf_out:\n",
    "        for line in gtf_in:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            if any(gene in line for gene in genes):\n",
    "                gtf_out.write(line)\n",
    "\n",
    "def extract_tss_bed(filtered_gtf, output_bed):\n",
    "    awk_cmd = (\n",
    "        '''awk '$3 == \"transcript\" {\n",
    "            match($0, /gene_id \"([^\"]+)\"/, m);\n",
    "            gene = m[1];\n",
    "            if ($7 == \"+\") {\n",
    "                print $1 \"\\\\t\" $4-1 \"\\\\t\" $4 \"\\\\t\" gene \"\\\\t.\\\\t\" $7;\n",
    "            } else {\n",
    "                print $1 \"\\\\t\" $5-1 \"\\\\t\" $5 \"\\\\t\" gene \"\\\\t.\\\\t\" $7;\n",
    "            }\n",
    "        }' '''\n",
    "    )\n",
    "    full_cmd = f\"{awk_cmd} {filtered_gtf} > {output_bed}\"\n",
    "    subprocess.run(full_cmd, shell=True, check=True)\n",
    "\n",
    "def create_promoter_bed(tss_bed, genome_sizes, output_bed, length=1000):\n",
    "    with open(output_bed, 'w') as out_f:\n",
    "        subprocess.run([\n",
    "            \"bedtools\", \"flank\",\n",
    "            \"-i\", tss_bed,\n",
    "            \"-g\", genome_sizes,\n",
    "            \"-l\", str(length),\n",
    "            \"-r\", \"0\",\n",
    "            \"-s\"\n",
    "        ], stdout=out_f, check=True)\n",
    "\n",
    "def extract_promoter_fasta(genome_fa, promoter_bed, output_fasta):\n",
    "    subprocess.run([\n",
    "        \"bedtools\", \"getfasta\",\n",
    "        \"-fi\", genome_fa,\n",
    "        \"-bed\", promoter_bed,\n",
    "        \"-fo\", output_fasta,\n",
    "        \"-s\",\n",
    "        \"-name\"  # preserves gene IDs in FASTA headers\n",
    "    ], check=True)\n",
    "\n",
    "# Functions to execute the above commands in parallel\n",
    "def run_promoter_pipeline(chunk_id, gene_list_chunk, gtf, genome_fa, genome_sizes, outdir):\n",
    "    filtered_gtf = f\"{outdir}/filtered_{chunk_id}.gtf\"\n",
    "    tss_bed = f\"{outdir}/tss_{chunk_id}.bed\"\n",
    "    promoter_bed = f\"{outdir}/promoters_{chunk_id}.bed\"\n",
    "    fasta_out = f\"{outdir}/promoters_{chunk_id}.fa\"\n",
    "\n",
    "    # Write chunked gene list\n",
    "    gene_list_file = f\"{outdir}/genes_{chunk_id}.txt\"\n",
    "    with open(gene_list_file, 'w') as f:\n",
    "        f.write('\\n'.join(gene_list_chunk))\n",
    "\n",
    "    # Run sub-steps\n",
    "    filter_gtf_by_genes(gtf, gene_list_file, filtered_gtf)\n",
    "    extract_tss_bed(filtered_gtf, tss_bed)\n",
    "    create_promoter_bed(tss_bed, genome_sizes, promoter_bed)\n",
    "    extract_promoter_fasta(genome_fa, promoter_bed, fasta_out)\n",
    "\n",
    "def parallel_promoter_extraction(genes_file, gtf, genome_fa, genome_sizes, outdir, num_cpus=10):\n",
    "    with open(genes_file) as f:\n",
    "        genes = f.read().splitlines()\n",
    "\n",
    "    # Split gene list into chunks\n",
    "    chunk_size = len(genes) // num_cpus\n",
    "    chunks = [genes[i:i + chunk_size] for i in range(0, len(genes), chunk_size)]\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    args = [(i, chunks[i], gtf, genome_fa, genome_sizes, outdir) for i in range(len(chunks))]\n",
    "    with multiprocessing.Pool(num_cpus) as pool:\n",
    "        pool.starmap(run_promoter_pipeline, args)\n",
    "\n",
    "    # Merge all .fa files\n",
    "    merged_fasta = os.path.join(outdir, \"promoters_merged.fa\")\n",
    "    with open(merged_fasta, 'w') as outfile:\n",
    "        for i in range(len(chunks)):\n",
    "            chunk_fasta = os.path.join(outdir, f\"promoters_{i}.fa\")\n",
    "            with open(chunk_fasta, 'r') as infile:\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "    print(\"‚úÖ All promoters extracted and merged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All promoters extracted and merged.\n",
      "‚úÖ Promoter FASTA extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# Run steps for Step 1\n",
    "parallel_promoter_extraction(\n",
    "    genes_file=gene_list,\n",
    "    gtf=gtf,\n",
    "    genome_fa=genome_fa,\n",
    "    genome_sizes=genome_sizes,\n",
    "    outdir=checkpoint_path,\n",
    "    num_cpus=10\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Promoter FASTA extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, I deleted all the unneccessary intermediate files and kept only the promoter_merged.fa file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I check that all the genes of interests have promoters that were saved in the merged promoter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found promoters for 32833 / 32833 genes.\n",
      "üéâ No missing genes.\n"
     ]
    }
   ],
   "source": [
    "def check_promoter_coverage(gene_list_file, promoters_fasta):\n",
    "    # Read expected gene list\n",
    "    with open(gene_list_file) as f:\n",
    "        expected_genes = set(f.read().splitlines())\n",
    "\n",
    "    # Read FASTA headers and extract gene IDs from lines like \"AT5G23180::5:...\"\n",
    "    with open(promoters_fasta) as f:\n",
    "        found_genes = set(\n",
    "            line[1:].strip().split(\"::\")[0]\n",
    "            for line in f if line.startswith(\">\")\n",
    "        )\n",
    "\n",
    "    missing = expected_genes - found_genes\n",
    "    extra = found_genes - expected_genes\n",
    "\n",
    "    print(f\"‚úÖ Found promoters for {len(found_genes)} / {len(expected_genes)} genes.\")\n",
    "    if missing:\n",
    "        print(f\"‚ùå Missing {len(missing)} genes:\")\n",
    "        for gene in list(missing)[:10]:\n",
    "            print(\"  \", gene)\n",
    "    else:\n",
    "        print(\"üéâ No missing genes.\")\n",
    "\n",
    "    if extra:\n",
    "        print(f\"‚ö†Ô∏è {len(extra)} unexpected gene(s) in output (not in your original list):\")\n",
    "        for gene in list(extra)[:5]:\n",
    "            print(\"  \", gene)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "check_promoter_coverage(\n",
    "    gene_list_file=gene_list,\n",
    "    promoters_fasta=\"/home/temccrac/Programs/cellular_clarity_project/checkpoints/promoters_merged.fa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # - Scan promoter sequences from each DPGP cluster for enriched motifs by comparing to a random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcriptomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
